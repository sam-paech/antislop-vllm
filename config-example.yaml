# Antislop-vLLM Configuration

# Note: values here will be overridden if cmdline params are specified.

# specify the url your vllm openai-compatible api is running at:
api_base_url: "http://localhost:8000/v1"
api_key: "xxx"

model_name: "unsloth/gemma-3-1b-it"


# Slop Configuration
slop_phrases_file: "banlists/slop_phrases.json"
top_n_slop_phrases: 200 # Use top N phrases from the file (assumes file is ordered)

# Generation Parameters
generation_params:
  threads: 40
  request_mode: chunk      # chunk | stream (stream might be buggy)
  chunk_size: 50  # if using chunk request_mode
  top_logprobs_count: 20
  max_new_tokens: 600
  temperature: 1.0
  top_p: 1.0
  top_k: 50
  min_p: 0.03
  
  # Inverts the probability distribution after other sampling modifications have been applied
  #    This encourages selection of the tail of the top n candidates, for more diverse outputs.
  #    You should probably only use this if using min_p to constrain the distribution.
  #    otherwise you will likely get incoherent completions.
  invert_probs: true
  timeout: 120        # seconds
  stop_sequences: []

# Backtracking Configuration
backtracking:
  max_retries_per_position: 20
  
  # If set to true:
  #   when resampling after backtracking, if we don't find a valid replacement token
  #   we progressively disable sampling options (temp, then min_p, then top_p, then top_k)
  #   until we find a non-banned replacement or run out of candidates.
  force_backtrack: true 

# N-Gram Validator Configuration (Optional)
ngram_validator:
  # Option 1: Specify a file containing a JSON list of banned n-grams
  # Each item in the JSON list can be a string (e.g., "this is an n gram")
  # or a list of strings (e.g., ["this", "is", "an", "n", "gram"])
  # banned_file: "banned_ngrams.json"

  # Option 2: Specify the list directly in the config
  # This takes precedence if banned_file is also specified but CLI overrides file.
  # CLI --ngram-banned-list overrides this.  
  banned_file: "banlists/banned_ngrams.json"

  #banned_list:
    # - "as an AI language model" # Will be tokenized
    # - "I am programmed"
    # - ["repeated", "phrase", "here"] # Already tokenized
    # - "feel free to ask"
  
  remove_stopwords: true # Default: true. Whether to remove stopwords before matching.
  language: "english"    # Default: "english". Language for stopwords.

# optional:
regex_blocklist_file: "banlists/regex_not_x_but_y.json"

# optional: output tokenwise dpo pairs
#tdpo_pairs_jsonl: "results/tdpo_pairs_run1.jsonl"

# Logging
logging_level: INFO