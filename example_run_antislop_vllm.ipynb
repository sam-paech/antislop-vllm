{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: load the model with vllm:\n",
    "\n",
    "# vllm serve unsloth/gemma-3-1b-it --port 8008 --max-model-len 2500 --served-model-name unsloth/gemma-3-1b-it --gpu-memory-utilization 0.8 --dtype bfloat16 --api-key xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6352a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7dcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Direct prompting mode. Returns a single unslopped output.\n",
    "\n",
    "if True:\n",
    "    cmd = [\n",
    "        'python3', 'main.py',\n",
    "        '--api-base-url', 'http://localhost:8000/v1',\n",
    "        '--api-key', 'xxx',\n",
    "        '--model-name', 'Qwen/Qwen3-4B',\n",
    "        '--chat-template-model-id', 'Qwen/Qwen3-4B',\n",
    "        '--logging-level', 'INFO',\n",
    "        '--slop-phrases-file', 'banlists/slop_phrases.json',\n",
    "        '--top-n-slop-phrases', '500',\n",
    "        '--regex-blocklist-file', 'banlists/regex_not_x_but_y.json',\n",
    "        '--max-new-tokens', '500',\n",
    "        '--prompt', 'Write a story about a princess. '\n",
    "    ]\n",
    "    print('Running:', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06e594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: python3 main.py --api-base-url https://attractions-intersection-char-regulations.trycloudflare.com/v1 --api-key xxx --model-name sam-paech/gemma-3-4b-it-antislop-exp35 --output-jsonl creative_writing_generations.jsonl --input-hf-dataset Nitral-AI/Reddit-SFW-Writing_Prompts_ShareGPT --hf-dataset-split train --threads 40 --max-prompts 40 --logging-level INFO --slop-phrases-file banlists/slop_phrases.jsonl --top-n-slop-phrases 500 --regex-blocklist-file banlists/regex_not_x_but_y.json --max-new-tokens 2000 --request-mode chunk --chunk-size 20 --chat-template-model-id unsloth/gemma-3-4b-it --ftpo-pairs-jsonl ftpo-pairs.jsonl\n",
      "INFO mode: Progress bar and ban events will be printed. Most logs suppressed. Effective script level: INFO\n",
      "Extracting HF prompts:   0%|          | 39/177477 [00:00<00:06, 28859.89prompt/s]\n",
      "Preparing to process 40 new prompts in this run.\n",
      "Batch Generating:   0%|          | 0/40 [00:00<?, ?prompt/s]start prefix builder\n",
      "built in 1.6437416076660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Generating:   0%|          | 0/40 [00:03<?, ?prompt/s, 16392.4 tok/s]filtering tail tokens for rejected token: ▁fluorescent\n",
      "adding ▁steel\n",
      "adding ▁grey\n",
      "BANNED (prompt_idx=5, type=ngram, ngram='fluorescent lights')              \n",
      "Batch Generating:   0%|          | 0/40 [00:03<?, ?prompt/s, 10368.3 tok/s]filtering tail tokens for rejected token: ▁first\n",
      "skipping ▁last\n",
      "adding ▁three\n",
      "adding ▁better\n",
      "adding ▁most\n",
      "adding ▁past\n",
      "BANNED (prompt_idx=13, type=ngram, ngram='first time')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:03<?, ?prompt/s, 9914.7 tok/s] filtering tail tokens for rejected token: ▁fluorescent\n",
      "adding ▁hum\n",
      "adding ▁grey\n",
      "adding ▁city\n",
      "filtering tail tokens for rejected token:BANNED (prompt_idx=29, type=ngram, ngram='fluorescent lights') \n",
      "▁first\n",
      "Batch Generating:   0%|          | 0/40 [00:04<?, ?prompt/s, 9116.7 tok/s]▁apartment\n",
      "adding ▁sticky\n",
      "adding ▁cool\n",
      "adding ▁little\n",
      "adding ▁dryness\n",
      "adding ▁tap\n",
      "adding ▁static\n",
      "adding ▁stick\n",
      "adding ▁initial\n",
      "adding ▁silence\n",
      "adding ▁smear\n",
      "adding ▁salt\n",
      "skipping ▁fluorescent\n",
      "adding ▁ghost\n",
      "adding ▁pink\n",
      "adding ▁chipped\n",
      "skipping ▁way\n",
      "adding ▁condensation\n",
      "adding ▁lavender\n",
      "BANNED (prompt_idx=8, type=ngram, ngram='first time')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:04<?, ?prompt/s, 3817.6 tok/s] ▁Dusting tail tokens for rejected token:\n",
      "Batch Generating:   0%|          | 0/40 [00:04<?, ?prompt/s, 3817.6 tok/s]adding ▁▁\n",
      "BANNED (prompt_idx=3, type=ngram, ngram='dust motes danced')              \n",
      "Batch Generating:   0%|          | 0/40 [00:04<?, ?prompt/s, 2724.3 tok/s]filtering tail tokens for rejected token: ▁Old\n",
      "skipping ▁Young\n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2729.9 tok/s]\n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2744.2 tok/s]▁My\n",
      "BANNED (prompt_idx=14, type=ngram, ngram='old man')                       \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2584.6 tok/s]filtering tail tokens for rejected token: ▁never\n",
      "adding ▁hunted\n",
      "adding ▁wrestled\n",
      "adding ▁tracked\n",
      "adding ▁chased\n",
      "adding ▁known\n",
      "adding ▁learned\n",
      "skipping ▁spent\n",
      "BANNED (prompt_idx=25, type=ngram, ngram='never seen')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2652.2 tok/s]filtering tail tokens for rejected token: ▁anything\n",
      "adding ▁I\n",
      "adding ▁it\n",
      "BANNED (prompt_idx=38, type=ngram, ngram='anything ever')                 \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2553.6 tok/s]filtering tail tokens for rejected token: ▁intricately\n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2559.9 tok/s]\n",
      "adding ▁–\n",
      "adding ▁iron\n",
      "adding ▁incredibly\n",
      "adding ▁surprisingly\n",
      "adding ▁complicated\n",
      "adding ▁silver\n",
      "adding ▁leather\n",
      "adding ▁polished\n",
      "adding ▁chain\n",
      "adding ▁what\n",
      "adding ▁intricate\n",
      "BANNED (prompt_idx=15, type=ngram, ngram='intricately carved wooden')     \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2569.4 tok/s]filtering tail tokens for rejected token: ▁looked\n",
      "adding ▁appeared\n",
      "adding ▁I\n",
      "BANNED (prompt_idx=16, type=ngram, ngram='looked like')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2538.7 tok/s]filtering tail tokens for rejected token: ▁carefully\n",
      "adding ▁cool\n",
      "adding ▁perfectly\n",
      "adding ▁precise\n",
      "adding ▁calculated\n",
      "adding ▁plac\n",
      "adding ▁tightly\n",
      "adding ▁glacial\n",
      "adding ▁mask\n",
      "adding ▁pleasant\n",
      "adding ▁picture\n",
      "adding ▁tight\n",
      "adding ▁controlled\n",
      "adding ▁study\n",
      "BANNED (prompt_idx=31, type=ngram, ngram='carefully constructed')         \n",
      "Batch Generating:   0%|          | 0/40 [00:05<?, ?prompt/s, 2531.5 tok/s]filtering tail tokens for rejected token: ▁fluorescent\n",
      "adding ▁entire\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='fluorescent lights')             \n",
      "Batch Generating:   0%|          | 0/40 [00:06<?, ?prompt/s, 2570.1 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁humble\n",
      "adding ▁farm\n",
      "adding ▁remarkably\n",
      "adding ▁boy\n",
      "adding ▁farmer\n",
      "adding ▁simple\n",
      "BANNED (prompt_idx=23, type=ngram, ngram='young man')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:06<?, ?prompt/s, 2489.8 tok/s]filtering tail tokens for rejected token: ▁carefully\n",
      "adding ▁established\n",
      "adding ▁comfort\n",
      "adding ▁usual\n",
      "BANNED (prompt_idx=33, type=ngram, ngram='carefully constructed')         \n",
      "Batch Generating:   0%|          | 0/40 [00:06<?, ?prompt/s, 2500.0 tok/s] ▁neverng tail tokens for rejected token:\n",
      "adding ▁honestly\n",
      "adding ▁only\n",
      "adding ▁rarely\n",
      "BANNED (prompt_idx=22, type=ngram, ngram='never seen')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:08<?, ?prompt/s, 2434.3 tok/s]filtering tail tokens for rejected token: ▁could\n",
      "skipping ▁knew\n",
      "adding ▁understood\n",
      "adding ▁heard\n",
      "adding ▁*\n",
      "BANNED (prompt_idx=10, type=ngram, ngram='could feel')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:08<?, ?prompt/s, 2399.9 tok/s]filtering tail tokens for rejected token: ▁not\n",
      "adding ▁so\n",
      "adding ▁afraid\n",
      "adding ▁terribly\n",
      "adding ▁supposed\n",
      "adding ▁sorry\n",
      "BANNED (prompt_idx=22, type=regex, regex='\\bnot\\s+(?:just|only|merely)?\\s*(?:(?!but\\b|[.?!]).){1,50}?[,;:—–-]?\\s*but\\s+(?:also\\s+)?', match='not supposed to do this, but ')\n",
      "Batch Generating:   0%|          | 0/40 [00:08<?, ?prompt/s, 2394.8 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁bored\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='young man')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:08<?, ?prompt/s, 2362.5 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁T\n",
      "adding -\n",
      "adding ▁work\n",
      "adding ▁shirt\n",
      "adding ▁t\n",
      "BANNED (prompt_idx=19, type=ngram, ngram='eyes wide')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:08<?, ?prompt/s, 2355.5 tok/s]filtering tail tokens for rejected token: ▁not\n",
      "adding ▁supposed\n",
      "adding ▁really\n",
      "adding ▁absolutely\n",
      "adding ▁*\n",
      "BANNED (prompt_idx=22, type=regex, regex='\\bnot\\s+(?:just|only|merely)?\\s*(?:(?!but\\b|[.?!]).){1,50}?[,;:—–-]?\\s*but\\s+(?:also\\s+)?', match='not supposed to do this, but ')\n",
      "Batch Generating:   0%|          | 0/40 [00:09<?, ?prompt/s, 2312.3 tok/s]filtering tail tokens for rejected token: ▁living\n",
      "adding ▁cellar\n",
      "adding ▁kitchen\n",
      "adding ▁glass\n",
      "skipping ▁back\n",
      "adding ▁window\n",
      "BANNED (prompt_idx=7, type=ngram, ngram='living room')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:10<?, ?prompt/s, 2268.7 tok/s]filtering tail tokens for rejected token: ▁would\n",
      "adding ▁summoned\n",
      "adding ▁settled\n",
      "skipping ▁could\n",
      "adding ▁couldn\n",
      "adding ▁didn\n",
      "adding ▁decided\n",
      "adding ▁wouldn\n",
      "adding '\n",
      "adding ▁needed\n",
      "adding ’\n",
      "BANNED (prompt_idx=23, type=ngram, ngram='would never')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:12<?, ?prompt/s, 2144.3 tok/s]filtering tail tokens for rejected token: ▁stark\n",
      "adding ▁study\n",
      "skipping ▁strange\n",
      "adding ▁chorus\n",
      "adding ▁human\n",
      "adding ▁mirror\n",
      "adding ▁fractured\n",
      "adding ▁tableau\n",
      "adding ▁visible\n",
      "adding ▁grey\n",
      "adding ▁messy\n",
      "adding ▁pale\n",
      "skipping ▁thick\n",
      "adding ▁heavy\n",
      "adding ▁sea\n",
      "adding ▁shared\n",
      "adding ▁visual\n",
      "adding ▁knot\n",
      "adding ▁wall\n",
      "adding ▁bizarre\n",
      "BANNED (prompt_idx=5, type=ngram, ngram='stark contrast')                 \n",
      "Batch Generating:   0%|          | 0/40 [00:12<?, ?prompt/s, 2062.0 tok/s]filtering tail tokens for rejected token: ▁one\n",
      "adding ▁human\n",
      "adding ▁weapon\n",
      "adding ▁harm\n",
      "adding ▁soul\n",
      "adding ▁mortal\n",
      "adding ▁matter\n",
      "adding ▁being\n",
      "adding ▁man\n",
      "skipping ▁living\n",
      "BANNED (prompt_idx=35, type=ngram, ngram='one could')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:12<?, ?prompt/s, 2056.9 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁weeping\n",
      "adding ▁grey\n",
      "adding ▁single\n",
      "adding ▁field\n",
      "adding ▁woman\n",
      "BANNED (prompt_idx=4, type=ngram, ngram='young woman')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:13<?, ?prompt/s, 2073.0 tok/s]filtering tail tokens for rejected token: ▁deep\n",
      "skipping ▁small\n",
      "adding ▁tentative\n",
      "skipping ▁breath\n",
      "adding ▁huge\n",
      "adding ▁hesitant\n",
      "adding ▁few\n",
      "skipping ▁step\n",
      "adding ▁monumental\n",
      "adding ▁shaky\n",
      "BANNED (prompt_idx=17, type=ngram, ngram='deep breath')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:14<?, ?prompt/s, 2148.4 tok/s]filtering tail tokens for rejected token: ▁air\n",
      "adding ▁terror\n",
      "adding ▁level\n",
      "adding ▁ghosts\n",
      "adding ▁raw\n",
      "adding ▁entire\n",
      "adding ▁dinosaurs\n",
      "adding ▁sheer\n",
      "adding ▁heat\n",
      "adding ▁logical\n",
      "skipping ▁old\n",
      "adding ▁calculations\n",
      "adding ▁memory\n",
      "adding ▁very\n",
      "adding ▁data\n",
      "adding ▁planet\n",
      "adding ▁logic\n",
      "adding ▁original\n",
      "adding ▁dominant\n",
      "adding ▁scale\n",
      "BANNED (prompt_idx=34, type=ngram, ngram='air thick')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:14<?, ?prompt/s, 2155.6 tok/s]filtering tail tokens for rejected token: ▁never\n",
      "adding ▁processed\n",
      "adding ▁scanned\n",
      "adding ▁only\n",
      "adding ,\n",
      "adding ▁examined\n",
      "adding ▁to\n",
      "skipping ▁seen\n",
      "BANNED (prompt_idx=2, type=ngram, ngram='never seen anything')            \n",
      "Batch Generating:   0%|          | 0/40 [00:14<?, ?prompt/s, 2095.8 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁clerk\n",
      "adding ▁polite\n",
      "adding ▁technician\n",
      "adding ▁woman\n",
      "BANNED (prompt_idx=25, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:15<?, ?prompt/s, 1981.4 tok/s]filtering tail tokens for rejected token: ▁ever\n",
      "adding ▁yet\n",
      "adding ▁previously\n",
      "skipping ▁seen\n",
      "BANNED (prompt_idx=7, type=ngram, ngram='ever seen')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:15<?, ?prompt/s, 1987.0 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁attention\n",
      "BANNED (prompt_idx=35, type=ngram, ngram='eyes locked')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:15<?, ?prompt/s, 2037.0 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁self\n",
      "adding ▁bright\n",
      "adding ▁brighter\n",
      "adding ▁woman\n",
      "adding ▁dream\n",
      "adding ▁drive\n",
      "adding ▁vibrant\n",
      "adding ▁life\n",
      "adding ▁better\n",
      "adding ▁more\n",
      "adding ▁girl\n",
      "adding ▁younger\n",
      "adding ▁person\n",
      "BANNED (prompt_idx=32, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:16<?, ?prompt/s, 2074.3 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁teenage\n",
      "adding ▁teenager\n",
      "adding ▁man\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='young man')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:16<?, ?prompt/s, 1986.1 tok/s]filtering tail tokens for rejected token: ▁left\n",
      "adding ▁built\n",
      "adding ▁produced\n",
      "adding ▁so\n",
      "adding ▁ignored\n",
      "adding ▁become\n",
      "adding ▁discarded\n",
      "adding ▁to\n",
      "skipping ▁spent\n",
      "adding ▁abandoned\n",
      "adding ▁rejected\n",
      "adding ▁considered\n",
      "adding ▁been\n",
      "BANNED (prompt_idx=37, type=ngram, ngram='left behind')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:16<?, ?prompt/s, 2018.5 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁man\n",
      "adding ▁boy\n",
      "skipping ▁one\n",
      "BANNED (prompt_idx=33, type=ngram, ngram='young man')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:17<?, ?prompt/s, 1901.8 tok/s]filtering tail tokens for rejected token: ▁one\n",
      "adding ▁rank\n",
      "adding ▁position\n",
      "skipping ▁last\n",
      "adding ▁coveted\n",
      "BANNED (prompt_idx=29, type=ngram, ngram='one would')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:17<?, ?prompt/s, 1976.0 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "Batch Generating:   0%|          | 0/40 [00:17<?, ?prompt/s, 1981.8 tok/s] ▁stressed\n",
      "adding ▁nervous\n",
      "adding ▁sweet\n",
      "adding ▁woman\n",
      "adding ▁teenage\n",
      "adding ▁teenager\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='young woman')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:17<?, ?prompt/s, 1954.8 tok/s]filtering tail tokens for rejected token: ▁long\n",
      "adding ▁very\n",
      "adding ▁solid\n",
      "adding ▁good\n",
      "BANNED (prompt_idx=20, type=ngram, ngram='long time')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:18<?, ?prompt/s, 1895.3 tok/s]filtering tail tokens for rejected token: ▁never\n",
      "adding ▁experienced\n",
      "adding ▁used\n",
      "skipping ▁spent\n",
      "skipping ▁run\n",
      "adding ▁scanned\n",
      "adding ▁designed\n",
      "adding ▁read\n",
      "adding ▁encountered\n",
      "adding ▁checked\n",
      "adding ▁only\n",
      "adding ▁been\n",
      "adding ▁heard\n",
      "adding ▁rarely\n",
      "skipping ▁seen\n",
      "BANNED (prompt_idx=2, type=ngram, ngram='never seen')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:18<?, ?prompt/s, 1878.4 tok/s]filtering tail tokens for rejected token: ▁maybe\n",
      "adding ▁you\n",
      "adding ▁we\n",
      "adding ▁if\n",
      "BANNED (prompt_idx=17, type=ngram, ngram='maybe maybe')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:18<?, ?prompt/s, 1891.0 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁Caleb\n",
      "adding ▁Elijah\n",
      "adding ▁child\n",
      "adding ▁certainly\n",
      "adding ▁a\n",
      "adding ▁I\n",
      "adding ▁you\n",
      "adding ▁Samuel\n",
      "adding ▁little\n",
      "adding ▁Mr\n",
      "adding ▁son\n",
      "BANNED (prompt_idx=0, type=ngram, ngram='young man')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:19<?, ?prompt/s, 1854.6 tok/s]▁makering tail tokens for rejected token: \n",
      "adding ▁*\n",
      "skipping ▁run\n",
      "adding ▁rationalize\n",
      "adding ▁move\n",
      "skipping ▁figure\n",
      "adding ▁think\n",
      "adding ▁look\n",
      "adding ▁track\n",
      "skipping ▁find\n",
      "adding ▁understand\n",
      "adding ▁analyze\n",
      "adding ▁reason\n",
      "adding ▁stop\n",
      "adding ▁trace\n",
      "adding ▁follow\n",
      "adding ▁be\n",
      "BANNED (prompt_idx=24, type=ngram, ngram='make sense')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:19<?, ?prompt/s, 1855.1 tok/s]filtering tail tokens for rejected token: ▁long\n",
      "adding ▁▁\n",
      "adding ▁couple\n",
      "adding ▁\n",
      "adding ▁two\n",
      "adding ▁amount\n",
      "BANNED (prompt_idx=9, type=ngram, ngram='long time')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:20<?, ?prompt/s, 1876.1 tok/s]filtering tail tokens for rejected token: ▁fabric\n",
      "adding ▁timeline\n",
      "adding ▁core\n",
      "adding ▁notion\n",
      "adding ▁purpose\n",
      "skipping ▁heart\n",
      "adding ▁pulse\n",
      "adding ▁threads\n",
      "adding ▁pattern\n",
      "adding ▁foundation\n",
      "adding ▁momentum\n",
      "adding ▁concept\n",
      "adding ▁flow\n",
      "adding ▁process\n",
      "adding ▁rhythm\n",
      "adding ▁structure\n",
      "adding ▁foundations\n",
      "adding ▁essence\n",
      "adding ▁*\n",
      "adding ▁nature\n",
      "BANNED (prompt_idx=21, type=ngram, ngram='fabric reality')                \n",
      "Batch Generating:   0%|          | 0/40 [00:20<?, ?prompt/s, 1822.1 tok/s]filtering tail tokens for rejected token: ▁dim\n",
      "adding ▁muted\n",
      "adding ▁fading\n",
      "adding ▁gathering\n",
      "adding ▁soft\n",
      "adding ▁half\n",
      "adding ▁grey\n",
      "adding ▁twilight\n",
      "adding ▁weak\n",
      "adding ▁near\n",
      "adding ▁failing\n",
      "skipping ▁growing\n",
      "adding ▁quiet\n",
      "adding ▁gloom\n",
      "BANNED (prompt_idx=26, type=ngram, ngram='dim light')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:20<?, ?prompt/s, 1828.5 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁younger\n",
      "adding ▁grizz\n",
      "adding ▁tall\n",
      "skipping ▁small\n",
      "adding ▁woman\n",
      "adding ▁man\n",
      "adding ▁child\n",
      "adding ▁bright\n",
      "adding ▁vibrant\n",
      "adding ▁little\n",
      "adding ▁strong\n",
      "adding ▁robust\n",
      "adding ▁solid\n",
      "adding ▁boy\n",
      "BANNED (prompt_idx=10, type=ngram, ngram='young man')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:21<?, ?prompt/s, 1861.2 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁son\n",
      "adding ▁my\n",
      "adding ▁Mr\n",
      "adding ▁Ben\n",
      "BANNED (prompt_idx=33, type=ngram, ngram='young man')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:21<?, ?prompt/s, 1810.1 tok/s]filtering tail tokens for rejected token: ▁first\n",
      "adding ▁most\n",
      "BANNED (prompt_idx=23, type=ngram, ngram='first time')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:22<?, ?prompt/s, 1793.6 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁silver\n",
      "skipping ▁hand\n",
      "adding ▁head\n",
      "adding ▁hands\n",
      "adding ▁eyebrows\n",
      "adding ▁grey\n",
      "adding ▁eyebrow\n",
      "adding ▁expression\n",
      "skipping ▁dark\n",
      "BANNED (prompt_idx=1, type=ngram, ngram='eyes narrowed')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:22<?, ?prompt/s, 1696.8 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁synthetic\n",
      "adding ▁lit\n",
      "adding ▁smooth\n",
      "adding ▁clinical\n",
      "adding ▁beautiful\n",
      "adding ▁bland\n",
      "adding ▁manufactured\n",
      "adding ▁flawless\n",
      "adding ▁triumphant\n",
      "adding ▁disturb\n",
      "adding ▁technically\n",
      "adding ▁flawlessly\n",
      "adding ▁clipped\n",
      "adding ▁collective\n",
      "adding ▁practiced\n",
      "adding ▁symphony\n",
      "adding ▁recording\n",
      "adding ▁polished\n",
      "adding ▁sacchar\n",
      "BANNED (prompt_idx=37, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:22<?, ?prompt/s, 1694.1 tok/s]filtering tail tokens for rejected token: ▁closed\n",
      "skipping ▁took\n",
      "adding ▁slumped\n",
      "adding ▁finally\n",
      "adding ▁visibly\n",
      "BANNED (prompt_idx=19, type=ngram, ngram='closed eyes')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:23<?, ?prompt/s, 1712.0 tok/s]filtering tail tokens for rejected token: ▁make\n",
      "adding ▁cross\n",
      "skipping ▁find\n",
      "adding ▁recognize\n",
      "adding ▁place\n",
      "adding ▁trace\n",
      "adding ▁identify\n",
      "adding ▁decipher\n",
      "adding ▁match\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='make sense')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:23<?, ?prompt/s, 1681.0 tok/s]filtering tail tokens for rejected token: ▁growing\n",
      "adding ▁immediate\n",
      "adding ▁feeling\n",
      "adding ▁burgeoning\n",
      "adding ▁flow\n",
      "adding ▁paralysis\n",
      "adding ▁rising\n",
      "adding ▁inevitable\n",
      "BANNED (prompt_idx=7, type=ngram, ngram='growing sense')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:23<?, ?prompt/s, 1668.4 tok/s]filtering tail tokens for rejected token: ▁unlike\n",
      "adding ▁sharper\n",
      "adding ▁somehow\n",
      "adding ▁completely\n",
      "adding ▁stunning\n",
      "adding ▁fascinating\n",
      "adding ▁the\n",
      "adding ▁beautiful\n",
      "adding ▁more\n",
      "adding ▁starting\n",
      "adding ▁so\n",
      "adding ▁breathtaking\n",
      "adding ▁both\n",
      "adding ▁remarkable\n",
      "adding ▁there\n",
      "adding ▁different\n",
      "adding ▁familiar\n",
      "adding ▁all\n",
      "adding ▁impressive\n",
      "skipping ▁almost\n",
      "adding ▁a\n",
      "BANNED (prompt_idx=8, type=ngram, ngram='unlike anything')                \n",
      "Batch Generating:   0%|          | 0/40 [00:24<?, ?prompt/s, 1663.8 tok/s]filtering tail tokens for rejected token: ▁raised\n",
      "adding ▁was\n",
      "adding ▁found\n",
      "adding ▁w\n",
      "adding ▁suddenly\n",
      "adding ▁extended\n",
      "adding ▁rose\n",
      "adding ▁considered\n",
      "skipping ▁tried\n",
      "adding ▁watched\n",
      "skipping ▁could\n",
      "adding ▁didn\n",
      "adding ▁stood\n",
      "BANNED (prompt_idx=38, type=ngram, ngram='raised hand')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:24<?, ?prompt/s, 1622.3 tok/s]filtering tail tokens for rejected token: ▁looked\n",
      "adding ▁was\n",
      "BANNED (prompt_idx=19, type=ngram, ngram='looked like')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:25<?, ?prompt/s, 1644.2 tok/s]filtering tail tokens for rejected token: ▁could\n",
      "adding ▁scanned\n",
      "skipping ▁caught\n",
      "adding ▁watched\n",
      "adding ▁saw\n",
      "BANNED (prompt_idx=22, type=ngram, ngram='could see')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:25<?, ?prompt/s, 1607.0 tok/s]filtering tail tokens for rejected token: ▁trying\n",
      "adding ▁pushing\n",
      "adding ▁watching\n",
      "adding ▁confirming\n",
      "adding ▁convinced\n",
      "adding ▁half\n",
      "adding ▁the\n",
      "adding ▁scanning\n",
      "adding ▁fighting\n",
      "adding ▁searching\n",
      "adding ▁willing\n",
      "adding ▁but\n",
      "adding ▁my\n",
      "BANNED (prompt_idx=22, type=ngram, ngram='trying make sense')             \n",
      "Batch Generating:   0%|          | 0/40 [00:26<?, ?prompt/s, 1639.9 tok/s]filtering tail tokens for rejected token: ▁breath\n",
      "adding ▁progress\n",
      "adding ▁senses\n",
      "adding ▁pulse\n",
      "adding ▁display\n",
      "skipping ▁hand\n",
      "adding ▁feet\n",
      "skipping ▁heart\n",
      "skipping ▁mind\n",
      "skipping ▁blood\n",
      "adding ▁tally\n",
      "BANNED (prompt_idx=29, type=ngram, ngram='breath caught')                 \n",
      "Batch Generating:   0%|          | 0/40 [00:27<?, ?prompt/s, 1635.3 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁high\n",
      "adding ▁familiar\n",
      "adding ▁younger\n",
      "adding ▁surge\n",
      "adding ▁riot\n",
      "adding ▁gl\n",
      "skipping ▁strange\n",
      "adding ▁tremor\n",
      "adding ▁child\n",
      "skipping ▁new\n",
      "adding ▁collective\n",
      "adding ▁sudden\n",
      "skipping ▁flicker\n",
      "adding ▁flash\n",
      "adding ▁glitch\n",
      "skipping ▁figure\n",
      "adding ▁group\n",
      "skipping ▁small\n",
      "BANNED (prompt_idx=37, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:27<?, ?prompt/s, 1636.3 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁child\n",
      "adding ▁teenage\n",
      "adding ▁teenager\n",
      "adding ▁little\n",
      "adding ▁girl\n",
      "BANNED (prompt_idx=21, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:28<?, ?prompt/s, 1622.8 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁girl\n",
      "adding ▁shock\n",
      "adding ▁riot\n",
      "adding ▁single\n",
      "adding ▁boy\n",
      "adding ▁Core\n",
      "adding ▁squad\n",
      "adding ▁few\n",
      "adding ▁woman\n",
      "adding ▁heavily\n",
      "skipping ▁new\n",
      "adding ▁security\n",
      "skipping ▁figure\n",
      "skipping ▁small\n",
      "adding ▁drone\n",
      "adding ▁flash\n",
      "adding ▁child\n",
      "adding ▁patrol\n",
      "adding ▁group\n",
      "BANNED (prompt_idx=37, type=ngram, ngram='young woman')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:28<?, ?prompt/s, 1611.8 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁I\n",
      "adding ▁Mr\n",
      "adding ▁my\n",
      "BANNED (prompt_idx=0, type=ngram, ngram='young man')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:29<?, ?prompt/s, 1666.3 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁Ben\n",
      "BANNED (prompt_idx=33, type=ngram, ngram='young man')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:29<?, ?prompt/s, 1624.2 tok/s]filtering tail tokens for rejected token: ▁couldn\n",
      "adding '\n",
      "adding ’\n",
      "skipping ▁never\n",
      "adding ▁didn\n",
      "skipping ▁could\n",
      "BANNED (prompt_idx=20, type=ngram, ngram='could quite')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:29<?, ?prompt/s, 1605.4 tok/s]filtering tail tokens for rejected token: ▁world\n",
      "adding ▁defense\n",
      "adding ▁being\n",
      "adding ▁existence\n",
      "adding ▁life\n",
      "BANNED (prompt_idx=35, type=ngram, ngram='world around')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:29<?, ?prompt/s, 1584.6 tok/s]filtering tail tokens for rejected token: ▁felt\n",
      "adding ▁must\n",
      "adding ▁seemed\n",
      "BANNED (prompt_idx=20, type=ngram, ngram='felt like')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:30<?, ?prompt/s, 1627.6 tok/s]filtering tail tokens for rejected token: ▁world\n",
      "adding ▁chain\n",
      "adding ▁*\n",
      "adding ▁bright\n",
      "adding ▁perfect\n",
      "adding ▁happy\n",
      "adding ▁specific\n",
      "adding ▁complex\n",
      "adding ▁reality\n",
      "adding ▁future\n",
      "adding ▁comfortable\n",
      "adding ▁ripple\n",
      "adding ▁stable\n",
      "adding ▁set\n",
      "adding ▁very\n",
      "skipping ▁new\n",
      "adding ▁completely\n",
      "adding ▁family\n",
      "adding ▁life\n",
      "adding ▁whole\n",
      "BANNED (prompt_idx=32, type=ngram, ngram='world around')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:31<?, ?prompt/s, 1527.4 tok/s]filtering tail tokens for rejected token: ▁one\n",
      "adding ▁as\n",
      "adding ▁just\n",
      "skipping ▁let\n",
      "adding ▁he\n",
      "adding ▁gave\n",
      "adding ▁then\n",
      "adding ▁and\n",
      "adding ▁his\n",
      "adding ▁really\n",
      "adding ▁a\n",
      "BANNED (prompt_idx=20, type=ngram, ngram='one last')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:31<?, ?prompt/s, 1565.1 tok/s]filtering tail tokens for rejected token: ▁one\n",
      "adding ▁a\n",
      "adding ▁me\n",
      "BANNED (prompt_idx=20, type=ngram, ngram='one last')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:33<?, ?prompt/s, 1622.0 tok/s]filtering tail tokens for rejected token: ▁stepped\n",
      "adding ▁was\n",
      "adding ▁watched\n",
      "adding ▁stood\n",
      "adding ▁didn\n",
      "BANNED (prompt_idx=24, type=ngram, ngram='stepped back')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:33<?, ?prompt/s, 1594.6 tok/s]filtering tail tokens for rejected token: ▁strange\n",
      "adding ▁very\n",
      "adding ▁nascent\n",
      "skipping ▁sense\n",
      "adding ▁tiny\n",
      "adding ▁different\n",
      "skipping ▁new\n",
      "BANNED (prompt_idx=32, type=ngram, ngram='strange sense')                 \n",
      "Batch Generating:   0%|          | 0/40 [00:33<?, ?prompt/s, 1582.7 tok/s][2025-06-02 06:39:11,543] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Batch Generating:   0%|          | 0/40 [00:34<?, ?prompt/s, 1562.0 tok/s]filtering tail tokens for rejected token: ▁world\n",
      "adding ▁entire\n",
      "adding ▁external\n",
      "adding ▁prisonfiltering tail tokens for rejected token:\n",
      " adding▁sound\n",
      "adding  ▁chaos▁ask\n",
      "\n",
      "addingadding ▁think\n",
      "adding ▁system\n",
      "adding ▁understand\n",
      "adding  ▁other▁have\n",
      "adding ▁know\n",
      "adding\n",
      " adding ▁want\n",
      "adding▁outside \n",
      "adding ▁even▁rest\n",
      "                                                                          \n",
      "BANNED (prompt_idx=38, type=ngram, ngram='sound like')\n",
      "BANNED (prompt_idx=5, type=ngram, ngram='world outside')                  \n",
      "Batch Generating:   0%|          | 0/40 [00:35<?, ?prompt/s, 1459.7 tok/s]filtering tail tokens for rejected token: Bare\n",
      "adding A\n",
      "adding M\n",
      "skipping Almost\n",
      "adding Quiet\n",
      "BANNED (prompt_idx=17, type=ngram, ngram='barely audible')                \n",
      "Batch Generating:   0%|          | 0/40 [00:35<?, ?prompt/s, 1465.1 tok/s]filtering tail tokens for rejected token: ▁new\n",
      "adding ▁Archives\n",
      "adding ▁cold\n",
      "adding ▁digital\n",
      "adding ▁data\n",
      "adding ▁archive\n",
      "adding ▁terminal\n",
      "adding ▁statistics\n",
      "adding ▁Pro\n",
      "adding ▁gray\n",
      "adding ▁city\n",
      "adding ▁screen\n",
      "adding ▁collection\n",
      "skipping ▁ever\n",
      "adding ▁Archive\n",
      "adding ▁grey\n",
      "skipping ▁world\n",
      "adding ▁Terminal\n",
      "adding ▁bleak\n",
      "adding ▁endless\n",
      "BANNED (prompt_idx=27, type=ngram, ngram='new world')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1479.3 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁iris\n",
      "adding ▁ir\n",
      "BANNED (prompt_idx=8, type=ngram, ngram='eyes wide')                      \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1467.4 tok/s]filtering tail tokens for rejected token: ▁first\n",
      "skipping ▁strange\n",
      "adding ▁soft\n",
      "adding ▁logic\n",
      "adding ▁guilt\n",
      "adding ▁system\n",
      "adding ▁knowledge\n",
      "adding ▁feeling\n",
      "adding ▁gray\n",
      "adding ▁fear\n",
      "adding ▁monitor\n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1463.7 tok/s]▁relief\n",
      "skipping ▁old\n",
      "adding ▁cool\n",
      "adding ▁grey\n",
      "adding ▁exhaustion\n",
      "adding ▁quiet\n",
      "adding ▁thought\n",
      "skipping ▁panic\n",
      "adding ▁weight\n",
      "adding ▁little\n",
      "BANNED (prompt_idx=32, type=ngram, ngram='first time')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1444.2 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "skipping ▁face\n",
      "adding ▁eye\n",
      "adding ▁blue\n",
      "adding ,\n",
      "adding ▁grey\n",
      "adding ly\n",
      "BANNED (prompt_idx=35, type=ngram, ngram='eyes locked')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1431.9 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "adding ▁screaming\n",
      "skipping ▁dark\n",
      "adding ▁woman\n",
      "adding ▁hospital\n",
      "adding ▁child\n",
      "BANNED (prompt_idx=4, type=ngram, ngram='young woman')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1420.9 tok/s]filtering tail tokens for rejected token: ▁could\n",
      "adding ▁finally\n",
      "adding ▁truly\n",
      "adding ▁did\n",
      "skipping ▁caught\n",
      "adding ▁recognized\n",
      "adding ▁was\n",
      "adding ▁wasn\n",
      "skipping ▁knew\n",
      "adding ▁saw\n",
      "adding ▁understood\n",
      "adding ▁*\n",
      "adding ▁didn\n",
      "BANNED (prompt_idx=35, type=ngram, ngram='could feel')                    \n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1488.7 tok/s]filtering tail tokens for rejected token: ▁raised\n",
      "Batch Generating:   0%|          | 0/40 [00:36<?, ?prompt/s, 1479.1 tok/s]\n",
      "adding ▁had\n",
      "adding ▁didn\n",
      "adding ▁scanned\n",
      "adding ▁saw\n",
      "adding ▁ran\n",
      "adding ▁was\n",
      "skipping ▁looked\n",
      "adding ▁adjusted\n",
      "adding ▁pulled\n",
      "adding ▁watched\n",
      "skipping ▁could\n",
      "BANNED (prompt_idx=26, type=ngram, ngram='raised hand')                   \n",
      "Batch Generating:   0%|          | 0/40 [00:37<?, ?prompt/s, 1434.3 tok/s]filtering tail tokens for rejected token: ▁cleared\n",
      "adding ▁lowered\n",
      "adding ▁added\n",
      "BANNED (prompt_idx=33, type=ngram, ngram='cleared throat')                \n",
      "Batch Generating:   0%|          | 0/40 [00:37<?, ?prompt/s, 1578.6 tok/s]filtering tail tokens for rejected token: ▁could\n",
      "adding ▁pulled\n",
      "adding ▁brought\n",
      "adding ▁initiated\n",
      "adding ▁scanned\n",
      "skipping ▁raised\n",
      "skipping ▁knew\n",
      "adding ▁immediately\n",
      "adding ▁saw\n",
      "adding ▁quickly\n",
      "skipping ▁caught\n",
      "skipping ▁looked\n",
      "adding ▁ran\n",
      "adding ▁ordered\n",
      "adding ▁had\n",
      "adding ▁watched\n",
      "adding ▁checked\n",
      "adding ▁was\n",
      "adding ▁realized\n",
      "adding ▁didn\n",
      "BANNED (prompt_idx=31, type=ngram, ngram='could see')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:38<?, ?prompt/s, 1454.7 tok/s]filtering tail tokens for rejected token: ▁long\n",
      "adding ,\n",
      "BANNED (prompt_idx=38, type=ngram, ngram='long time')                     \n",
      "Batch Generating:   0%|          | 0/40 [00:38<?, ?prompt/s, 1545.9 tok/s]<|user|>\n",
      "Writing prompt: Write a short story where the first sentence has 20 words, 2nd sentence has 19, 3rd has 18 etc. Story ends with a single word.\n",
      "\n",
      "Write 1000 words to\n",
      "<|assistant|>\n",
      "The antique music box, a heavy, tarnished silver, suddenly began to play a haunting, unfamiliar melody. A chill permeated the small, dusty attic, raising goosebumps on my exposed arms despite the late summer heat. The chipped porcelain ballerina inside, frozen mid-pirouette, suddenly caught my eye, a delicate, silent protest. I hadn't been in this forgotten space of my grandmother’s house for nearly twenty years, a lifetime, it seemed, sliding by with painful, dull certainty.  The scent of lavender and old paper, intensely sweet and melancholy, immediately assaulted my senses, pulling me back to a childhood I’d mostly tried to forget. It wasn't the expected sadness of grief, or regret, but a deeper, pervasive loneliness, an understanding that time truly had moved relentlessly on. \n",
      "\n",
      "I hadn’t known my grandmother, Evelyn, well. I’d spent my childhood with my parents in the city, a city\n",
      "Batch Generating:   0%|          | 0/40 [00:38<?, ?prompt/s, 1558.3 tok/s]<|user|>\n",
      "Writing prompt: On one hand, you're average at everything. On the other hand, you're average at EVERYTHING.\n",
      "\n",
      "Write 1000 words to this prompt. Your response:\n",
      "\n",
      "<|assistant|>\n",
      "The chipped mug, a cheerful robin's egg blue, is permanently stained with the ghost of Earl Grey. It’s perfectly, frustratingly, average. I’ve had it for seven years. Seven years of lukewarm tea, slightly burnt toast, and the quiet, persistent hum of a life that's consistently, reliably, and entirely unremarkable. \n",
      "\n",
      "That's the thing, isn't it? I’m good at being unremarkable. \n",
      "\n",
      "I can fold fitted sheets – I’ll probably be around 78% successful, maybe a little better, maybe slightly worse. I can make a decent, but forgettable, spaghetti carbonara. My attempts at watercolor painting always look like a sad, slightly judgmental impressionist’s fever dream. I can hold down a job, a perfectly pleasant but thoroughly unexciting position as a data entry clerk at Miller & Finch, an accounting firm that has never quite grown beyond a comfortable, beige-toned\n",
      "<|user|>\n",
      "Writing prompt: Eminem has to tell the history of the earth to a group of aliens in 5 minuets or less.\n",
      "\n",
      "Write 1000 words to this prompt. Your response:\n",
      "\n",
      "<|assistant|>\n",
      "(Beat drops - heavy 808s, distorted synth stabs, and a nervous, ticking clock sample. Eminem’s instantly recognizable cadence is aggressive, rapid-fire, and laced with barely-contained frustration.)\n",
      "\n",
      "Yo, check the mic, one two. They callin’ me Slim Shady, but tonight, I’m more like Slim History.  Five minutes.  Five *bleeping* minutes to drop the whole damn story?  Don't look so shocked, little green fellas. You want the blueprint, the dirt, the *everything*?  This is it.  Let's go.\n",
      "\n",
      "(Beat intensifies – a driving, almost industrial pulse)\n",
      "\n",
      "Alright, picture this.  Before you, *before everything you’re seeing*, there was *nothin’*.  Just a void. A dark, angry, expanding, lonely, theoretical soup.  We call it the early universe.  Quantum physics\n",
      "Batch Generating:   0%|          | 0/40 [00:39<?, ?prompt/s, 1500.9 tok/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 256). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Generating:   0%|          | 0/40 [00:39<?, ?prompt/s, 1486.2 tok/s]filtering tail tokens for rejected token: ▁one\n",
      "adding ▁with\n",
      "adding ▁perhaps\n",
      "adding ▁at\n",
      "adding ▁in\n",
      "adding ▁eventually\n",
      "BANNED (prompt_idx=17, type=ngram, ngram='one day')                       \n",
      "Batch Generating:   0%|          | 0/40 [00:39<?, ?prompt/s, 1548.7 tok/s]False 0.91015625 Non-refusal\n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1548.7 tok/s]<|user|>\n",
      "Writing prompt: My German Shepard had to be put down today. We never knew where he came from. Please write about his adventures.\n",
      "\n",
      "Write 1000 words to this prompt. Your response:\n",
      "<|assistant|>\n",
      "The silence in the house is a tangible thing, a grey, heavy blanket smothering every corner. It used to be filled with the happy, clumsy rush of a German Shepherd, a joyous, panting welcome at the door, and the persistent, gentle nudge of his head against my hand. Now, it just sits.  It's a silence that screams of absence, a constant, painful record of a beautiful, complicated life, a life I never truly knew the beginning of. \n",
      "\n",
      "His name was Shadow. How he got it, I honestly can’t say. I found him as a lanky, nervous adolescent, abandoned behind the local animal shelter. He was a tangle of awkward angles and hesitant steps, a gorgeous, mottled grey blur with a deep, soulful brown eye that held an ancient sadness. He'd cower at sudden noises, snap at anyone who rushed, and just generally look lost.  I, a recently heartbroken, newly single\n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1485.7 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁blue\n",
      "adding -\n",
      "BANNED (prompt_idx=11, type=ngram, ngram='eyes never leaving')                    \n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1475.6 tok/s]filtering tail tokens for rejected token: ▁young\n",
      "skipping ▁figure\n",
      "adding ▁thought\n",
      "adding ▁security\n",
      "adding ▁soft\n",
      "adding ▁booming\n",
      "adding ▁collective\n",
      "adding ▁man\n",
      "adding ▁calm\n",
      "skipping ▁deep\n",
      "adding ▁high\n",
      "adding ▁clear\n",
      "adding ▁quiet\n",
      "adding ▁child\n",
      "adding ▁librarian\n",
      "skipping ▁hand\n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1468.3 tok/s]\n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1473.2 tok/s]skipping ▁small\n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1479.2 tok/s]▁little\n",
      "skipping ▁new\n",
      "BANNED (prompt_idx=6, type=ngram, ngram='young man')                              \n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1471.0 tok/s] ▁stepped tail tokens for rejected token:\n",
      "adding ▁launched\n",
      "adding ▁didn\n",
      "adding ,\n",
      "BANNED (prompt_idx=22, type=ngram, ngram='stepped forward')                       \n",
      "Batch Generating:   2%|▎         | 1/40 [00:39<25:38, 39.45s/prompt, 1462.5 tok/s]False 0.9609375 Non-refusal\n",
      "Batch Generating:   5%|▌         | 2/40 [00:39<10:24, 16.44s/prompt, 1506.8 tok/s]False 0.88671875 Non-refusal\n",
      "Batch Generating:   8%|▊         | 3/40 [00:40<05:33,  9.02s/prompt, 1482.9 tok/s]filtering tail tokens for rejected token: ▁eyes\n",
      "adding ▁lips\n",
      "adding ing\n",
      "adding ▁reflection\n",
      "adding ▁tone\n",
      "adding ,\n",
      "adding -\n",
      "adding ▁ghost\n",
      "adding ▁a\n",
      "adding ▁features\n",
      "adding ▁expression\n",
      "skipping ▁face\n",
      "BANNED (prompt_idx=2, type=ngram, ngram='eyes filled')                            \n",
      "Batch Generating:   8%|▊         | 3/40 [00:40<05:33,  9.02s/prompt, 1531.0 tok/s]False 0.96484375 Non-refusal\n",
      "Batch Generating:  10%|█         | 4/40 [00:40<03:21,  5.61s/prompt, 1531.0 tok/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-15:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m\n\u001b[1;32m     15\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmain.py\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--api-base-url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://attractions-intersection-char-regulations.trycloudflare.com/v1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--ftpo-pairs-jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftpo-pairs.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m ]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(cmd))\n\u001b[0;32m---> 36\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    505\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1144\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1941\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1940\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1941\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1899\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1899\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1901\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1903\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1904\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example 2: Generate an unslopped dataset using prompts from a huggingface sharegpt dataset\n",
    "\n",
    "# Make sure you've launched the vllm openai-compatible server first. You can use something like:\n",
    "\n",
    "# vllm serve unsloth/gemma-3-4b-it --port 8000 --max-model-len 2500 --served-model-name unsloth/gemma-3-4b-it --gpu-memory-utilization 0.95 --dtype bfloat16 --api-key xxx\n",
    "\n",
    "\n",
    "THREADS  = 40\n",
    "MAX_PROMPTS = 40\n",
    "\n",
    "OUT_JSONL     = 'creative_writing_generations.jsonl'\n",
    "HUMAN_PROFILE = 'data/human_writing_profile.json'\n",
    "\n",
    "\n",
    "cmd = [\n",
    "    'python3', 'main.py',\n",
    "    '--api-base-url', 'https://attractions-intersection-char-regulations.trycloudflare.com/v1',\n",
    "    '--api-key', 'xxx',\n",
    "    '--model-name', 'sam-paech/gemma-3-4b-it-antislop-exp35',    \n",
    "    '--output-jsonl', OUT_JSONL,\n",
    "    '--input-hf-dataset', 'Nitral-AI/Reddit-SFW-Writing_Prompts_ShareGPT',        \n",
    "    '--hf-dataset-split', 'train',\n",
    "    '--threads', str(THREADS),\n",
    "    '--max-prompts', str(MAX_PROMPTS),\n",
    "    '--logging-level', 'INFO',\n",
    "    '--slop-phrases-file', 'banlists/slop_phrases.jsonl',\n",
    "    '--top-n-slop-phrases', '500',    \n",
    "    '--regex-blocklist-file', 'banlists/regex_not_x_but_y.json',\n",
    "    '--max-new-tokens', '2000',\n",
    "    '--request-mode', 'chunk',  # chunk / stream (stream mode might be buggy)\n",
    "    '--chunk-size', '20', # how many tokens we request from the api before checking it for new violations\n",
    "    '--chat-template-model-id', \"unsloth/gemma-3-4b-it\",\n",
    "    '--ftpo-pairs-jsonl', 'ftpo-pairs.jsonl'\n",
    "]\n",
    "print('Running:', ' '.join(cmd))\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
